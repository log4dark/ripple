from transformers import T5Tokenizer, T5ForConditionalGeneration

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = T5Tokenizer.from_pretrained("KETI-AIR/ke-t5-small")
model = T5ForConditionalGeneration.from_pretrained("KETI-AIR/ke-t5-small")

def t5_summarize(text: str) -> str:
    """
    T5 ëª¨ë¸ì„ ì´ìš©í•œ ë¬¸ì¥ ì •ë¦¬ (ëª…ë ¹í˜• prefix ì‚¬ìš©)
    ì˜ˆ: "ë¬¸ì¥ ì •ë¦¬: ~" â†’ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±
    """
    prefix = "ë¬¸ì¥ ì •ë¦¬: "
    input_text = prefix + text

    input_ids = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)

    output_ids = model.generate(
        input_ids,
        max_length=128,
        num_beams=4,
        early_stopping=True
    )

    return tokenizer.decode(output_ids[0], skip_special_tokens=True)


if __name__ == "__main__":
    sample = "ì—ì´í‹° ê³ ê°ì„¼í„°ì…ë‹ˆë‹¤ ê¸°ê°€ì¸í„´ ì— í‹°ë¹„ ë“± ìœ ì„ ìƒí’ˆì€ ì¼ ë²ˆ í•˜ì´ ì˜¤ë” ì—ì´ì•„ì´ë¡œë´‡ ì‹œì‹œí‹°ë¹„ ë“± ì°½ì—…ê³ ê° ê°€ê²Œë§¤ì¥ ìƒí’ˆì€ ì´ ë²ˆ íœ´ëŒ€í°ì€ ì„ ë°œì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"
    print("ğŸ“ T5 ì •ë¦¬ ê²°ê³¼:", t5_summarize(sample))

