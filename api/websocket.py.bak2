# api/websocket.py

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import os
import wave
import numpy as np
from datetime import datetime
import webrtcvad

from utils.log import setup_logger
from model.loader import get_model
from model.transcribe import stream_transcribe

router = APIRouter()
logger = setup_logger("websocket")

AUDIO_DIR = "temp_audio"
os.makedirs(AUDIO_DIR, exist_ok=True)

SAMPLE_RATE = 16000
CHUNK_SECONDS = 5
OVERLAP_SECONDS = 0.5
OVERLAP_SIZE = int(SAMPLE_RATE * OVERLAP_SECONDS)

# WebRTC VAD ì„¤ì •
# - 3ì´ˆ ì´ìƒ or 300ms ì´ìƒ ë¬´ìŒì´ë©´ STT ìˆ˜í–‰
VAD_FRAME_MS = 30 # 1 í”„ë ˆì„ = 30ms
VAD_FRAME_SIZE = int(SAMPLE_RATE * VAD_FRAME_MS / 1000)
SILENCE_TRIGGER_FRAMES = 17 # ë¬´ìŒ íŠ¸ë¦¬ê±° ì¡°ê±´: 500ms = 30ms Ã— 17 â‰’ 510ms
#SILENCE_TRIGGER_FRAMES = 10  # ë¬´ìŒ 300ms ê¸°ì¤€
vad = webrtcvad.Vad(2)  # ë¯¼ê°ë„: 0 (ê°€ì¥ ë¯¼ê°) ~ 3 (ê°€ì¥ ë‘”ê°)

model = get_model()

@router.websocket("/ws/stt/stream")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
    filepath = os.path.join(AUDIO_DIR, filename)

    frames = bytearray()
    buffer = []
    pcm_buffer = np.array([], dtype=np.int16)
    silence_buffer = []
    vad_silence_count = 0
    prev_tail = np.array([], dtype=np.int16)

    logger.info(f"ğŸ™ï¸ WebSocket ì—°ê²° ìˆ˜ë¦½ë¨ â†’ {filename}")

    try:
        while True:
            data = await websocket.receive_bytes()
            frames.extend(data)
            chunk = np.frombuffer(data, dtype=np.int16)
            buffer.append(chunk)
            pcm_buffer = np.concatenate(buffer)

            while len(pcm_buffer) >= VAD_FRAME_SIZE:
                frame = pcm_buffer[:VAD_FRAME_SIZE]
                pcm_buffer = pcm_buffer[VAD_FRAME_SIZE:]

                audio_bytes = frame.tobytes()
                if vad.is_speech(audio_bytes, SAMPLE_RATE):
                    vad_silence_count = 0
                    silence_buffer.append(frame)
                else:
                    vad_silence_count += 1
                    silence_buffer.append(frame)

                duration_ms = len(silence_buffer) * VAD_FRAME_MS
                if vad_silence_count >= SILENCE_TRIGGER_FRAMES or duration_ms >= CHUNK_SECONDS * 1000:
                    logger.debug("[ì²­í¬ ì²˜ë¦¬ ì‹œì‘] ----------------------------")
                    current = np.concatenate(silence_buffer)

                    # ì˜¤ë²„ë© ì ìš©
                    if prev_tail.size > 0:
                        full = np.concatenate([prev_tail, current])
                    else:
                        full = current
                    prev_tail = current[-OVERLAP_SIZE:]

                    logger.debug(f"STT í”„ë ˆì„ ê¸¸ì´: {len(full)}")
                    segments, result = stream_transcribe(model, full, sr=SAMPLE_RATE)

                    # ì¤‘ë³µ ì œê±°
                    filtered_segments = []
                    last_end = 0.0
                    for seg in segments:
                        if seg.start >= last_end - 0.3:
                            filtered_segments.append(seg)
                            last_end = seg.end
                        else:
                            logger.debug(f"ì¤‘ë³µ ì œê±°ë¨: {seg.start:.2f}-{seg.end:.2f} â†’ {seg.text}")

                    result_text = " ".join([s.text for s in filtered_segments]).strip()

                    if result_text:
                        logger.info(f"ì‹¤ì‹œê°„ STT ê²°ê³¼ (ì¤‘ë³µì œê±°): {result_text[:50]}...")
                        await websocket.send_text(result_text)
                    else:
                        logger.debug("ì‹¤ì‹œê°„ STT ê²°ê³¼ ì—†ìŒ")

                    logger.debug("[ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ] ----------------------------\n")
                    silence_buffer = []
                    vad_silence_count = 0
                    buffer = [pcm_buffer] if len(pcm_buffer) > 0 else []

    except WebSocketDisconnect:
        logger.warning(f"â— WebSocket ì—°ê²° ëŠê¹€ â†’ {filename}")
        try:
            with wave.open(filepath, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(SAMPLE_RATE)
                wf.writeframes(frames)
            logger.info(f"ğŸ’¾ WAV ì €ì¥ ì™„ë£Œ â†’ {filepath} ({len(frames)} bytes)")
        except Exception as e:
            logger.error(f"ğŸš¨ WAV ì €ì¥ ì‹¤íŒ¨ â†’ {filepath} | ì˜¤ë¥˜: {str(e)}")
